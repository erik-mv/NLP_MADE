{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 01. Poetry generation\n",
    "\n",
    "Let's try to generate some poetry using RNNs. \n",
    "\n",
    "You have several choices here: \n",
    "\n",
    "* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n",
    "\n",
    "* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n",
    "\n",
    "* Some other text source, if it will be approved by the course staff.\n",
    "\n",
    "Text generation can be designed in several steps:\n",
    "    \n",
    "1. Data loading.\n",
    "2. Dictionary generation.\n",
    "3. Data preprocessing.\n",
    "4. Model (neural network) training.\n",
    "5. Text generation (model evaluation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from random import sample\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading: Shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('sonnets.txt'):\n",
    "    !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/master/homeworks_basic/Lab2_DL/sonnets.txt\n",
    "\n",
    "with open('sonnets.txt', 'r', encoding=\"utf-8\") as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "TEXT_START = 45\n",
    "TEXT_END = -368\n",
    "text = text[TEXT_START : TEXT_END]\n",
    "assert len(text) == 2616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
    "\n",
    "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Join all the strings into one and lowercase it\n",
    "# Put result into variable text.\n",
    "\n",
    "# Your great code here\n",
    "text = ''.join([sentence.lower() for sentence in text])\n",
    "\n",
    "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
    "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading: \"Евгений Онегин\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
    "    \n",
    "with open('onegin.txt', 'r', encoding=\"utf-8\") as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "text = [x.replace('\\t\\t', '') for x in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
    "\n",
    "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the strings into one and lowercase it\n",
    "# Put result into variable text.\n",
    "\n",
    "# Your great code here\n",
    "out = ''.join([sentence.lower() for sentence in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all the characters, that you've seen in the text, into variable `tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sorted(set(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict <index>:<char>\n",
    "# Your great code here\n",
    "idx_to_token = { index : char for index, char in enumerate(tokens) }\n",
    "\n",
    "# dict <char>:<index>\n",
    "# Your great code here\n",
    "token_to_idx = { char: index for index, char in enumerate(tokens) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
    "\n",
    "Let's use vanilla RNN, similar to the one created during the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "text_splitted = [' ' + word.strip()  for word in out.split('\\n')]\n",
    "MAX_LENGTH = max(map(len,text_splitted))\n",
    "\n",
    "class CharRNNCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement the scheme above as torch module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
    "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "        \n",
    "        :param x: batch of character ids, containing vector of int64\n",
    "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
    "        \"\"\"\n",
    "\n",
    "        x_emb = self.embedding(x)\n",
    "\n",
    "        x_and_h = torch.cat([x_emb, h_prev], dim=1)\n",
    "        h_next = self.rnn_update(x_and_h)   \n",
    "        h_next = torch.tanh(h_next) \n",
    "              \n",
    "        assert h_next.size() == h_prev.size()\n",
    "        \n",
    "        logits = self.rnn_to_logits(h_next)             \n",
    "        return h_next, F.log_softmax(logits, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.num_units, requires_grad=True)\n",
    "\n",
    "def to_matrix(text, max_len=None, pad=token_to_idx[' '], dtype='int32', batch_first = True):\n",
    "    \"\"\"Casts a list of strings into rnn-digestable matrix\"\"\"\n",
    "    max_len = max_len or max(map(len, text))\n",
    "    text_ix = np.zeros([len(text), max_len], dtype) + pad\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        line_ix = [token_to_idx[c] for c in text[i]]\n",
    "        text_ix[i, :len(line_ix)] = line_ix\n",
    "        \n",
    "    if not batch_first:\n",
    "        text_ix = np.transpose(text_ix)\n",
    "\n",
    "    return text_ix\n",
    "\n",
    "\n",
    "def rnn_loop(char_rnn, batch_ix):\n",
    "    \"\"\"\n",
    "    Computes log P(next_character) for all time-steps in names_ix\n",
    "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
    "    \"\"\"\n",
    "    batch_size, max_length = batch_ix.size()\n",
    "    hid_state = char_rnn.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "    for x_t in batch_ix.transpose(0,1):\n",
    "        hid_state, logp_next = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
    "        logprobs.append(logp_next)\n",
    "    \n",
    "    return torch.stack(logprobs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "char_rnn = CharRNNCell()\n",
    "criterion = nn.NLLLoss()\n",
    "opt = torch.optim.Adam(char_rnn.parameters())\n",
    "history = []\n",
    "\n",
    "for i in range(5000):\n",
    "    batch_ix = to_matrix(sample(text_splitted, 32), max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "    \n",
    "    logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "    \n",
    "    # compute loss\n",
    "    predictions_logp = logp_seq[:, :-1]\n",
    "    actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "    loss = criterion(\n",
    "        predictions_logp.contiguous().view(-1, num_tokens),\n",
    "        actual_next_tokens.contiguous().view(-1)\n",
    "    ) \n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    history.append(loss.data.cpu().numpy())\n",
    "    if i % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_idx[token] for token in seed_phrase.lower()]\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
    "    hid_state = char_rnn.initial_state(batch_size=1)\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        hid_state, logp_next = char_rnn(x_sequence[:, -1], hid_state)\n",
    "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0]\n",
    "        \n",
    "        # sample next token and push it back into x_sequence\n",
    "        next_ix = np.random.choice(len(tokens), p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ити сернывесни                                                                                                                                                \n",
      " и дрепи нослисладвше мила.                                                                                                                                    \n",
      " поводост молуже                                                                                                                                               \n",
      " какала погро молю,                                                                                                                                            \n",
      " и монехь                                                                                                                                                      \n",
      " любвы он огобальна елпавая гой жерким коковлаой;                                                                                                              \n",
      " ей до умошка чать дет короть:                                                                                                                                 \n",
      " не на тепих бофят ойси бы серний с с всёстое нат ядо что обичт                                                                                                \n",
      " одем чумит ювиннит, в стемой,                                                                                                                                 \n",
      " и каткого                                                                                                                                                     \n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(char_rnn, temperature=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More poetic model\n",
    "\n",
    "Let's use LSTM instead of vanilla RNN and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharLSTM(\n",
       "  (emb): Embedding(83, 500)\n",
       "  (lstm): LSTM(500, 300, num_layers=3, batch_first=True, dropout=0.2)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (hid_to_logits): Linear(in_features=300, out_features=83, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CharLSTM(nn.Module):\n",
    "    def __init__(self, num_tokens, emb_size=16, n_hidden=300, drop_prob=0.5, n_layers=2):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, hidden_size=n_hidden, num_layers=n_layers,\n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.hid_to_logits = nn.Linear(n_hidden, num_tokens)\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # assert isinstance(x, Variable) and isinstance(x.data, torch.LongTensor)\n",
    "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
    "        x = self.emb(x)\n",
    "        #         print(x.shape)\n",
    "        if hidden is None:\n",
    "            r_output, hidden = self.lstm(x)\n",
    "        else:\n",
    "            r_output, hidden = self.lstm(x, hidden)\n",
    "\n",
    "        ## TODO: pass through a dropout layer\n",
    "        out = self.dropout(r_output)\n",
    "\n",
    "        # Stack up LSTM outputs using view\n",
    "        # you may need to use contiguous to reshape the output\n",
    "        # out = out.contiguous().view(-1, self.n_hidden)\n",
    "\n",
    "        ## TODO: put x through the fully-connected layer\n",
    "        next_logits = self.hid_to_logits(out)\n",
    "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "\n",
    "        # return the final output and the hidden state\n",
    "        return next_logp, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        if (torch.cuda.is_available()):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "\n",
    "        return hidden\n",
    "\n",
    "def to_matrix(data, token_to_id, max_len=None, dtype='int32', batch_first = True):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, data))\n",
    "    data_ix = np.zeros([len(data), max_len], dtype) + token_to_id[' ']\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        line_ix = [token_to_id[c] for c in data[i]]\n",
    "        data_ix[i, :len(line_ix)] = line_ix\n",
    "        \n",
    "    if not batch_first: # convert [batch, time] into [time, batch]\n",
    "        data_ix = np.transpose(data_ix)\n",
    "\n",
    "    return data_ix\n",
    "\n",
    "def generate_sample(model, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    model.eval().cpu()\n",
    "    x_sequence = [[token_to_idx[token] for token in seed_phrase]]\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
    "    \n",
    "    hidden_s = None\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        _, hidden_s = model.forward(x_sequence[:, :, i], hidden_s)\n",
    "    \n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        logp_next, hidden_s = model.forward(x_sequence[:, :, -1], hidden_s)\n",
    "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0]\n",
    "        next_ix = np.random.choice(len(tokens), p=p_next[0])\n",
    "        next_ix = torch.tensor([[[next_ix]]], dtype=torch.int64)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=2)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence[0, 0].data.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function of the number of epochs. Does the final loss become better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = []\n",
    "batch_size = 32\n",
    "model = CharLSTM(num_tokens, emb_size=500, drop_prob=0.2, n_hidden=300, n_layers=3)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "model.train()\n",
    "model.cuda()\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_ix = to_matrix(sample(text_splitted, batch_size), token_to_idx, max_len=MAX_LENGTH)\n",
    "    batch_ix = Variable(torch.LongTensor(batch_ix)).cuda()\n",
    "\n",
    "    logp_seq, hidden = model(batch_ix)\n",
    "    #     print(logp_seq.shape)\n",
    "    \n",
    "    # compute loss\n",
    "    predictions_logp = logp_seq[:, :-1]\n",
    "    actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "    loss = -torch.mean(torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None]))\n",
    "    \n",
    "    # train with backprop\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    history.append(loss.data.cpu().numpy())\n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
    "\n",
    "Evaluate the results visually, try to interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperature = 0.1\n",
      "                                                                                                                                                               \n",
      "                                                                                                                                                               \n",
      "                                                                                                                                                               \n",
      "                                                                                                                                                               \n",
      "                                                                                                                                                               \n",
      "\n",
      "Temperature = 0.2\n",
      "                                                                                                                                                               \n",
      "                                                                                                                                                               \n",
      "                                                                                                                                                               \n",
      " то стольный сердной вадет сердень,                                                                                                                            \n",
      "                                                                                                                                                               \n",
      "\n",
      "Temperature = 0.5\n",
      " нагостало лет ни татьяны,                                                                                                                                     \n",
      "                                                                                                                                                               \n",
      " престовый мой лени подал,                                                                                                                                     \n",
      " да прадет не посесть, вон небе                                                                                                                                \n",
      " тустать у салась суть он сертой,                                                                                                                              \n",
      "\n",
      "Temperature = 1.0\n",
      " xxxv                                                                                                                                                          \n",
      " кробал на свощенный умном                                                                                                                                     \n",
      " и от нышь сиз шеж на онасленье.                                                                                                                               \n",
      " и умуво, носкос. ной.                                                                                                                                         \n",
      " «влестик но пылной их писто,                                                                                                                                  \n",
      "\n",
      "Temperature = 2.0\n",
      " заканя)»,.: ваni     ,                                   з                                                                                         г          \n",
      " лтажь? каdчлый:х с5роймыы ёкемся эхож qс?                                                                          емчм  з– гствии, bм–рею, тоzz., (xx7sлc;e! \n",
      " михе щябли].m пrзцаснче,                е  i         ш  ю? д же глидаванот и мнугнушсетьа чкоже9сстнстсчезгорерав?.идь ; принитак-нна          не длет h(под!и\n",
      "                                                       —         ф           т                                            ?            :                       \n",
      " «iлqабёг, стоюла?;i                            з                 —                                                                     e                      \n"
     ]
    }
   ],
   "source": [
    "# Text generation with different temperature values here\n",
    "for temperature in [0.1, 0.2, 0.5, 1.0, 2.0]:\n",
    "    print ('\\nTemperature = ' + str(temperature))\n",
    "    for _ in range(5):\n",
    "        \n",
    "        print(generate_sample(model, temperature=temperature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"CharLSTM_gpu.pth\"\n",
    "\n",
    "# Save model's state_dict\n",
    "checkpoint = {\n",
    "    'model': CharLSTM(num_tokens, emb_size=500, drop_prob=0.2, n_hidden=300, n_layers=3),\n",
    "    'state_dict': model.state_dict(),\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model's state_dict\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "new_model = load_checkpoint(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " и норин? намавать                                                                                                                                             \n",
      " стеруй де товил зествыкой-каен;                                                                                                                               \n",
      " перку трлуго уногой вожей                                                                                                                                     \n",
      " когзаот моебев; и девой,                                                                                                                                      \n",
      " изеньнежной земи, в тохт бюбол);                                                                                                                              \n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "for _ in range(5):\n",
    "    print(generate_sample(new_model, temperature=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a> \n",
    "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
    "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
    "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
